<!DOCTYPE html>
<html>
  <head>
    <title>Introduction to Genetic Programming</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body {
          font-family: 'Droid Serif';
      }

      h1, h2, h3 {
          font-family: 'Yanone Kaffeesatz';
          font-weight: 400;
          margin-bottom: 0;
      }

      .remark-slide-content h1 { font-size: 3em; }
      .remark-slide-content h2 { font-size: 2em; }
      .remark-slide-content h3 { font-size: 1.6em; }
      .footnote {
          position: absolute;
          bottom: 3em;
      }

      li p { line-height: 1.25em; }
      .red { color: #fa0000; }
      .large { font-size: 2em; }

      a, a > code {
          color: rgb(249, 38, 114);
          text-decoration: none;
      }

      code {
          -moz-border-radius: 5px;
          -web-border-radius: 5px;
          background: #e7e8e2;
          border-radius: 5px;
      }

      img {
        display: block;
        margin-top: 5%;
      }

      iframe {
        margin-top: 7%;
      }

      .footnote {

      }

      .title_page {
        padding-top: 25%;
        text-align: center;
      }

      .center {
        display: block;
        height: 1024px;
      }

      .center img {
        max-width: 100%;
        max-height: 40%;
        margin-left: auto;
        margin-right: auto;
      }

      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code-line-highlighted { background-color: #373832; }

      .pull-left {
          float: left;
          width: 47%;
      }

      .pull-right {
          float: right;
          width: 47%;
      }

      .pull-right ~ p {
          clear: both;
      }

      .middle-middle-custom {
        width: 80%;
        margin-top: 15%;
        margin-left: auto;
        margin-right: auto;
        font-size: 1.5em;
        text-align: justify;
      }

      .middle-middle-custom img {
        margin-left: auto;
        margin-right: auto;
      }

      .middle-custom {
        width: 80%;
        padding-top: 5%;
        margin-left: auto;
        margin-right: auto;
      }

      #slideshow .slide .content code {
          font-size: 0.8em;
      }

      #slideshow .slide .content pre code {
          font-size: 0.9em;
          padding: 15px;
      }

      .inverse {
          background: #272822;
          color: #777872;
          text-shadow: 0 0 20px #333;
      }

      .inverse h1, .inverse h2 {
          color: #f3f3f3;
          line-height: 0.8em;
      }

      /* Slide-specific styling */
      #slide-inverse .footnote {
          bottom: 12px;
          left: 20px;
      }

      #slide-how .slides {
          font-size: 0.9em;
          position: absolute;
          top: 151px;
          right: 140px;
      }

      #slide-how .slides h3 {
          margin-top: 0.2em;
      }

      #slide-how .slides .first, #slide-how .slides .second {
          padding: 1px 20px;
          height: 90px;
          width: 120px;
          -moz-box-shadow: 0 0 10px #777;
          -webkit-box-shadow: 0 0 10px #777;
          box-shadow: 0 0 10px #777;
      }

      #slide-how .slides .first {
          background: #fff;
          position: absolute;
          top: 20%;
          left: 20%;
          z-index: 1;
      }

      #slide-how .slides .second {
          position: relative;
          background: #fff;
          z-index: 0;
      }

      /* Two-column layout */
      .left-column {
          color: #777;
          width: 30%;
          height: 92%;
          float: left;
      }

      .left-column h2:last-of-type, .left-column h3:last-child {
          color: #000;
      }

      .left-column h3 {
          margin-top: 0.5em;
      }

      .right-column {
          width: 60%;
          float: right;
          padding-top: 1em;
      }

      .right-column img {
          max-width: 90%;
      }

    </style>
  </head>
  <body>
    <textarea id="source">

name: inverse
layout: true
class: title_page, inverse
---
# Introduction to Evolutionary Algorithms
[chris choi]

---

layout: false

# Search Methods

.middle-middle-custom[
    ![search methods classification](./images/search_methods_classification.jpg)
]

---

# Evolutionary Algorithms

.middle-middle-custom[
- Evolutionary Algorithms are known to be **Meta-Heuristic Algorithms**

- **"I don't know what the answer looks like, but I will know it when I see it"**
]

---

name: inverse
layout: true
class: title_page, inverse

---

# How does it work?

---

layout: false

# Evolutionary Algorithm - General Idea

.center[
    ![evolutionary algorithm form](./images/evolutionary_algorithm.png)
]

---

.left-column[
## Evolutionary Algorithm Requirements
### - Input Data
]

.right-column[
## Input Data
Depending on the problem, input training data maybe required
as a stimuli to encourage the algorithm to explore the search space.

For example:
- Symbolic Regression
- Classification
- Robotic Control

For problems that are self-play such as *GO* or *Chess*, input data is **not
needed**, because it is a unsupervised learning.
]

---

.left-column[
## Evolutionary Algorithm Requirements
### - Input Data
### - Problem Encoding
]

.right-column[
## Problem Encoding
Encode the "chromosome" to represent a potential solution on the problem at
hand.

For example, in curve fitting the chromosome is the mathematical equation,
represented in a Tree data structure.

.center[![Tree](./images/gp_tree.png)]
]

---

.left-column[
## Evolutionary Algorithm Requirements
### - Input Data
### - Problem Encoding
### - Fitness Function
]

.right-column[
## Fitness Function
A function that is capable of comparing individuals. It is also known as the

- **Evaluation Function**
- **Cost Function**
- etc...

For example in **Regression** a possible fitness function could be **Sum Squared
Errors**.
]

---

.left-column[
## Evolutionary Algorithm Requirements
### - Input Data
### - Problem Encoding
### - Fitness Function
### - Genetic Operators
]

.right-column[
## Genetic Operators
These operators are responsible for modifying the candidate solution (hopefully
for the better).

For example:

- Selection
- Crossover
- Mutation

Operators.
]


---

name: inverse
layout: true
class: title_page, inverse

---

# But what can it do?

---

layout: false

.left-column[
## Example Applications
### - Symbolic Regression
]

.right-column[
### Symbolic Regression
Similar to Curve Fitting, the goal is to find the best model that fits the data

.center[
    ![symbolic regression](./images/symbolic_regression.png)
]
]

---

.left-column[
## Example Applications
### - Symbolic Regression
]

.right-column[
### Symbolic Regression
To perform Symbolic Regression, we represent the candidate solutions (i.e. an
equation) in the form of a Tree Data Structure.

.center[
    ![gp tree](./images/gp_tree.png)
]
]

---

.left-column[
## Example Applications
### - Symbolic Regression
]

.right-column[
### Symbolic Regression
Demo of [playground](http://github.com/chutsu/playground) solving toy problems

.center[
<iframe
    width="500"
    height="300"
    src="//www.youtube.com/embed/dPjBrLjSBl4"
    frameborder="0"
    allowfullscreen
>
</iframe>
]
]

---

.left-column[
## Example Applications
### - Symbolic Regression
### - Classification
]

.right-column[
  ### Classification
  Using a Tree data structure again, the algorithm can evolve a decision tree
  to solve classification problems.

  ![gp classification](./images/make_circles.png)
]

---

.center[
    ![gp classification](./images/make_circles.png)
]

---

.center[
    ![gp classification](./images/make_circles_roc.png)
]

---

.left-column[
## Example Applications
### - Symbolic Regression
### - Classification
### - Neuro Evolution
]

.right-column[
### Neuro Evolution

<iframe
    width="500
    " height="300"
    src="//www.youtube.com/embed/qv6UVOQ0F44"
    frameborder="0"
    allowfullscreen
>
</iframe>
]

---

name: inverse
layout: true
class: title_page, inverse

---

# Pros and Cons

---

layout: false

# Advantages
.middle-custom[
## - No Prior Assumtions Required
## - Good for not well understood problems
## - Inherently Parallel
## - Domain Independent
]

---

# Disadvantages
.middle-custom[
## - Takes a lot of compute resources
## - Have to define a good fitness function
## - Optimal parameters can be difficult
## - Bloat
]

---

name: inverse
layout: true
class: title_page, inverse

---

# Questions?

---

# References

---

layout: false

### References

- Arabas, Z. Michalewicz, and J. Mulawka. Gavaps-a genetic algorithm
with varying population size. In Evolutionary Computation, 1994. IEEE
World Congress on Computational Intelligence., Proceedings of the First
IEEE Conference on, pages 73–78 vol.1, 1994.

- Jeff Clune, Sheni Goings, Bill Punch, and Eric Goodman. Investigations in
meta-gas: Panaceas or pipe dreams? In Proceedings of the 2005 Workshops
on Genetic and Evolutionary Computation, GECCO ’05, pages 235–241,
New York, NY, USA, 2005. ACM.

- Kenneth De Jong. Parameter setting in eas: a 30 year perspective. In
FernandoG. Lobo, ClÃąudioF. Lima, and Zbigniew Michalewicz, editors,
Parameter Setting in Evolutionary Algorithms, volume 54 of Studies in
Computational Intelligence, pages 1–18. Springer Berlin Heidelberg, 2007.

- Stefan Droste, Thomas Jansen, and Ingo Wegener. Optimization with ran-
domized search heuristics – the (a)nfl theorem, realistic scenarios, and dif-
ficult functions. THEORETICAL COMPUTER SCIENCE, 287:113–114,
2002.

---

### References - 2

- A.E. Eiben, R. Hinterding, and Z. Michalewicz. Parameter control in evo-
lutionary algorithms. Evolutionary Computation, IEEE Transactions on,
3(2):124–141, 1999.

- A.E. Eiben and S.K. Smit. Evolutionary algorithm parameters and methods
to tune them. In Youssef Hamadi, Eric Monfroy, and FrÃľdÃľric Saubion,
editors, Autonomous Search, pages 15–36. Springer Berlin Heidelberg, 2012.

- David E. Goldberg. Genetic Algorithms in Search, Optimization and Ma-
chine Learning. Addison-Wesley Longman Publishing Co., Inc., Boston,
MA, USA, 1st edition, 1989.

- Youssef Hamadi, Eric Monfroy, and FrÃľdÃľric Saubion. An introduction
to autonomous search. In Youssef Hamadi, Eric Monfroy, and FrÃľdÃľric
Saubion, editors, Autonomous Search, pages 1–11. Springer Berlin Heidel-
berg, 2012.

- Y.-C. Ho and D.L. Pepyne. Simple explanation of the no free lunch theorem
14of optimization. In Decision and Control, 2001. Proceedings of the 40th
IEEE Conference on, volume 5, pages 4409–4414 vol.5, 2001.

---

### References - 3

- J. H. Holland. Adaptation in Natural and Artificial Systems. The University
of Michigan Press, 1975.

- Christian Igel and Marc Toussaint. A no-free-lunch theorem for non-
uniform distributions of target functions. Journal of Mathematical Mod-
elling and Algorithms, 3(4):313–322, 2005.

- John R Koza. Genetic Programming: vol. 1, On the programming of com-
puters by means of natural selection, volume 1. MIT press, 1992.

- Oded Maron and Andrew W. Moore. The racing algorithm: Model selection
for lazy learners. Artificial Intelligence Review, 11:193–225, 1997.

- Riccardo Poli, W William B Langdon, Nicholas F McPhee, and John R
Koza. A field guide to genetic programming. Lulu. com, 2008.

---

### References - 4

- I. Rechenberg. Evolutionsstrategie 94, volume 1 of Werkstatt Bionik und
Evolutionstechnik. Frommann-Holzboog, Stuttgart, 1994.

- C. Schumacher, M. D. Vose, and L. D. Whitley. The no free lunch and
problem description length. In Proceedings of the Genetic and Evolution-
ary Computation Conference (GECCO-2001, pages 565–570. Morgan Kauf-
mann, 2001.

- M. Srinivas and L.M. Patnaik. Adaptive probabilities of crossover and mu-
tation in genetic algorithms. Systems, Man and Cybernetics, IEEE Trans-
actions on, 24(4):656–667, 1994.

- Matthew J. Streeter. Two broad classes of functions for which a no free lunch
result does not hold. In Erick Cant-Paz, JamesA. Foster, Kalyanmoy
Deb, LawrenceDavid Davis, Rajkumar Roy, Una-May O'Reilly, Hans-
Georg Beyer, Russell Standish, Graham Kendall, Stewart Wilson, Mark
Harman, Joachim Wegener, Dipankar Dasgupta, MitchA. Potter, AlanC.
Schultz, KathrynA. Dowsland, Natasha Jonoska, and Julian Miller, editors,
Genetic and Evolutionary Computation GECCO 2003, volume 2724
of Lecture Notes in Computer Science, pages 1418–1430. Springer Berlin
Heidelberg, 2003.

---

### References - 5

- D.H. Wolpert and W.G. Macready. No free lunch theorems for optimization.
Evolutionary Computation, IEEE Transactions on, 1(1):67–82, 1997.

- D.H. Wolpert and W.G. Macready. Coevolutionary free lunches. Evolutionary
Computation, IEEE Transactions on, 9(6):721–735, 2005.

- J.R. Woodward. Ga or gp? that is not the question. In Evolutionary
Computation, 2003. CEC ’03. The 2003 Congress on, volume 2, pages
1056–1063 Vol.2, 2003.

- B. Yuan and M. Gallagher. Combining Meta-EAs and Racing for Difficult
EA Parameter Tuning Tasks. In F.G. Lobo, C.F. Lima, and Z. Michalewicz,
editors, Parameter Setting in Evolutionary Algorithms, pages 121–142.
Springer, 2007.

    </textarea>
    <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>

     <!-- MATHJAX -->
     <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
            TeX: { equationNumbers: { autoNumber: "AMS" }}
        });
     </script>
     <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"> </script>
  </body>
</html>
